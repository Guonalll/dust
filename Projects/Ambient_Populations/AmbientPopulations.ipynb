{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambient Populations\n",
    "\n",
    "Some early experiments with 'ambient' population data from various sources to assess their use in COVID-19 related projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # requirement beautifulsoup4\n",
    "from urllib.request import (\n",
    "    urlopen, urlparse, urlunparse, urlretrieve)\n",
    "import os, os.path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leeds Footfall cameras\n",
    "\n",
    "Leeds City Council run a network of 8 cameras that count the number of passers-by every hour. The data are publicly available on [Data Mill North](https://datamillnorth.org/dataset/leeds-city-centre-footfall-data).\n",
    "\n",
    "We have already done quite a lot of analysis with those data elsewhere so wont repeat that here. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download\n",
    "\n",
    "Each month is reported in a different file, but it's quite easy to parse the html and get the urls for each file.\n",
    "\n",
    "The next block saves each file in the directory [./data/lcc_footfall](./data/lcc_footfall) creating those directories if necessary.\n",
    "\n",
    "If a file is already in that directory it doesn't re-dowload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Mar%202020.csv exists already, not downloading\n",
      "File Mar%202020.csv exists already, not downloading\n",
      "File Mar%202020.csv exists already, not downloading\n",
      "File Feb%202020.csv exists already, not downloading\n",
      "File Feb%202020.csv exists already, not downloading\n",
      "File Feb%202020.csv exists already, not downloading\n",
      "File Jan%202020.csv exists already, not downloading\n",
      "File Jan%202020.csv exists already, not downloading\n",
      "File Jan%202020.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Nov%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Nov%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Nov%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20October%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20October%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20October%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20feed%20September%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20feed%20September%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20feed%20September%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-August%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-August%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-August%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Mar%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Mar%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Mar%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Feb%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Feb%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Feb%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Jan%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Jan%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Jan%202019.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20feed%20-%20Nov%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20feed%20-%20Nov%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20feed%20-%20Nov%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Sept%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Sept%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Sept%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Sept%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Sept%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Sept%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20August%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20August%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20August%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20July%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20July%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20July%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20June%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20June%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20June%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20May%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20May%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20May%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20April%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20April%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20April%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-March%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-March%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-March%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-Feb%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-Feb%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-Feb%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20%20Jan%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20%20Jan%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20%20Jan%202018.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Nov%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Nov%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20Nov%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20%20August%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20%20August%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20%20August%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20July%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20July%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20July%202017.csv exists already, not downloading\n",
      "File Monthy%20Data%20Feed%20-%20June%202017.csv exists already, not downloading\n",
      "File Monthy%20Data%20Feed%20-%20June%202017.csv exists already, not downloading\n",
      "File Monthy%20Data%20Feed%20-%20June%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20May%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20May%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed%20-%20May%202017.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-April%202017%20-%2020170510.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-April%202017%20-%2020170510.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-April%202017%20-%2020170510.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-October%202016%20-%2020161102.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-October%202016%20-%2020161102.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-October%202016%20-%2020161102.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-September%202016%20-%2020161102.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-September%202016%20-%2020161102.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-September%202016%20-%2020161102.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-Apr%202016%20-%2020160501.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-Apr%202016%20-%2020160501.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-Apr%202016%20-%2020160501.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-Jan%202016%20-%2020160222.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-Jan%202016%20-%2020160222.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-Jan%202016%20-%2020160222.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-November%202015%20-%2020151203.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-November%202015%20-%2020151203.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-November%202015%20-%2020151203.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-October%202015%20-%2020151203.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-October%202015%20-%2020151203.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-October%202015%20-%2020151203.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-September%202015%20-%2020151012.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-September%202015%20-%2020151012.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-September%202015%20-%2020151012.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-August%202015%20-%2020150917.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-August%202015%20-%2020150917.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-August%202015%20-%2020150917.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-July%202015%20-%2020150807.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-July%202015%20-%2020150807.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-July%202015%20-%2020150807.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-June%202015%20-%2020150703%20(4).csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-June%202015%20-%2020150703%20(4).csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-June%202015%20-%2020150703%20(4).csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-May%202015%20-%2020150601%20(1).csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-May%202015%20-%2020150601%20(1).csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-May%202015%20-%2020150601%20(1).csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-April%202015%20-%2020150507.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-April%202015%20-%2020150507.csv exists already, not downloading\n",
      "File Monthly%20Data%20Feed-April%202015%20-%2020150507.csv exists already, not downloading\n",
      "File monthly-data-feed-jan-2015-20150205.csv exists already, not downloading\n",
      "File monthly-data-feed-jan-2015-20150205.csv exists already, not downloading\n",
      "File monthly-data-feed-jan-2015-20150205.csv exists already, not downloading\n",
      "File monthly-data-feed-dec-2014-20150108.csv exists already, not downloading\n",
      "File monthly-data-feed-dec-2014-20150108.csv exists already, not downloading\n",
      "File monthly-data-feed-dec-2014-20150108.csv exists already, not downloading\n",
      "File monthly-data-feed-nov-2014-20141205.csv exists already, not downloading\n",
      "File monthly-data-feed-nov-2014-20141205.csv exists already, not downloading\n",
      "File monthly-data-feed-nov-2014-20141205.csv exists already, not downloading\n",
      "File monthly-data-feed-oct-2014-20141107.csv exists already, not downloading\n",
      "File monthly-data-feed-oct-2014-20141107.csv exists already, not downloading\n",
      "File monthly-data-feed-oct-2014-20141107.csv exists already, not downloading\n",
      "File monthly-data-feed-sept-2014-20141009.csv exists already, not downloading\n",
      "File monthly-data-feed-sept-2014-20141009.csv exists already, not downloading\n",
      "File monthly-data-feed-sept-2014-20141009.csv exists already, not downloading\n",
      "File monthly-data-feed-aug-2014-20140904.csv exists already, not downloading\n",
      "File monthly-data-feed-aug-2014-20140904.csv exists already, not downloading\n",
      "File monthly-data-feed-aug-2014-20140904.csv exists already, not downloading\n",
      "File monthly-data-feed-july-2014-20140811.csv exists already, not downloading\n",
      "File monthly-data-feed-july-2014-20140811.csv exists already, not downloading\n",
      "File monthly-data-feed-july-2014-20140811.csv exists already, not downloading\n",
      "File monthly-data-feed-june-2014-20140710.csv exists already, not downloading\n",
      "File monthly-data-feed-june-2014-20140710.csv exists already, not downloading\n",
      "File monthly-data-feed-june-2014-20140710.csv exists already, not downloading\n",
      "Downloading footfall.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File footfall.csv exists already, not downloading\n",
      "File footfall.csv exists already, not downloading\n",
      "File headrow.csv exists already, not downloading\n",
      "File headrow.csv exists already, not downloading\n",
      "File headrow.csv exists already, not downloading\n",
      "File dortmund-square.csv exists already, not downloading\n",
      "File dortmund-square.csv exists already, not downloading\n",
      "File dortmund-square.csv exists already, not downloading\n",
      "File commercial-street-at-lush.csv exists already, not downloading\n",
      "File commercial-street-at-lush.csv exists already, not downloading\n",
      "File commercial-street-at-lush.csv exists already, not downloading\n",
      "File commercial-street-at-barratts.csv exists already, not downloading\n",
      "File commercial-street-at-barratts.csv exists already, not downloading\n",
      "File commercial-street-at-barratts.csv exists already, not downloading\n",
      "File briggate.csv exists already, not downloading\n",
      "File briggate.csv exists already, not downloading\n",
      "File briggate.csv exists already, not downloading\n",
      "File briggate-at-mcdonalds.csv exists already, not downloading\n",
      "File briggate-at-mcdonalds.csv exists already, not downloading\n",
      "File briggate-at-mcdonalds.csv exists already, not downloading\n",
      "File albion-street-north.csv exists already, not downloading\n",
      "File albion-street-north.csv exists already, not downloading\n",
      "File albion-street-north.csv exists already, not downloading\n",
      "File albion-street-south.csv exists already, not downloading\n",
      "File albion-street-south.csv exists already, not downloading\n",
      "File albion-street-south.csv exists already, not downloading\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/lcc_footfall\" # Where to save the csv files\n",
    "if not os.path.isdir(data_dir):\n",
    "    print(\"Creating data directory {}\".format(data_dir))\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Connect to the Data Mill North page and parse the html\n",
    "root = 'https://datamillnorth.org/dataset/leeds-city-centre-footfall-data'\n",
    "soup = BeautifulSoup(urlopen(root), 'html.parser')\n",
    "\n",
    "# Iterate over all links and see which are csv files\n",
    "for link in soup.find_all('a'):\n",
    "    #print(\"\\n****\",link,\"****\\n\")\n",
    "    url = link.get('href')\n",
    "    if url==None: # if no 'href' tag\n",
    "        continue\n",
    "    \n",
    "    if url.endswith(\".csv\"):\n",
    "        filename = url.strip().split(\"/\")[-1] # File is last part of the url\n",
    "        \n",
    "        # For some reason some files are duplicated\n",
    "        if filename.startswith(\"Copy\") or filename.startswith(\"copy\"): \n",
    "            continue\n",
    "        # And we don't care about xmas analysis\n",
    "        if filename.startswith(\"Christ\"):\n",
    "            continue\n",
    "        \n",
    "        # Save the csv file (unless it already exists already)\n",
    "        full_path = os.path.join(\"./data/lcc_footfall\",filename)\n",
    "        if os.path.isfile(full_path):\n",
    "            print(\"File {} exists already, not downloading\".format(filename))\n",
    "        else:\n",
    "            print(\"Downloading {}\".format(filename)) \n",
    "            csv_url = \"https://datamillnorth.org/\"+url\n",
    "            data = pd.read_csv(csv_url)\n",
    "            data.to_csv(full_path)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read each of those files and create one big dataframe to store all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Monthly%20Data%20Feed%20-%20%20Jan%202018.csv has nans in the following columns: '['Hour']'. Ignoring it\n",
      "File Monthly%20Data%20Feed%20-%20Dec%202017.csv has nans in the following columns: '['Hour']'. Ignoring it\n",
      "File Monthly%20Data%20Feed%20-%20Nov%202017.csv has nans in the following columns: '['Hour']'. Ignoring it\n",
      "File Monthly%20Data%20Feed-April%202017%20-%2020170510.csv has nans in the following columns: '['Date', 'InCount', 'Hour', 'Location']'. Ignoring it\n",
      "File Monthly%20Data%20Feed-Feb%202018.csv has nans in the following columns: '['Hour']'. Ignoring it\n",
      "File Monthly%20Data%20Feed-March%202018.csv has nans in the following columns: '['Hour']'. Ignoring it\n",
      "Finished. Made a dataframe with 646294 rows. 6/58 files could not be read.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_hour(series):\n",
    "    \"\"\"Assumes the given series represents hours. Works out if they're \n",
    "    integers or in the format '03:00:00' and returns them as integers\"\"\"\n",
    "    \n",
    "    # If it's a number then just return it\n",
    "    if isinstance(series.values[0], np.int64) or isinstance(series.values[0], np.float64) or isinstance(series.values[0], float):\n",
    "        return series\n",
    "    \n",
    "    # If it's a string see if it can be made into a number\n",
    "    try:\n",
    "        int(series.values[0])\n",
    "        return pd.to_numeric(series)\n",
    "    except: # If get here then it couldn't be made into an integer\n",
    "        pass\n",
    "    \n",
    "    if \":\" in series.values[0]:\n",
    "        return pd.to_numeric(series.apply(lambda x: x.strip().split(\":\")[0]))\n",
    "    \n",
    "    # If here then I don't know what to do.\n",
    "    raise Exception(\"Unrecognised type of hours: {}\".format(series))\n",
    "    \n",
    "# Template for our data frame. Set the type as well (default is OK for 'location')\n",
    "template = pd.DataFrame(columns = [\"Location\", \"Date\", \"Hour\", \"Count\", \"DateTime\"])\n",
    "template[\"Date\"] = pd.to_datetime(template[\"Date\"])\n",
    "template[\"Hour\"] = pd.to_numeric(template[\"Hour\"])\n",
    "template[\"Count\"] = pd.to_numeric(template[\"Count\"])\n",
    "template[\"DateTime\"] = pd.to_numeric(template[\"DateTime\"]) # (this one is derived from date and hour)\n",
    "\n",
    "frames = [] # Build up a load of dataframes then merge them\n",
    "total_rows = 0 # For checking that the merge works\n",
    "files = [] # Remember the names of the files we tried to analyse\n",
    "failures= [] # Remember which ones didn't work\n",
    "\n",
    "\n",
    "# Read the files in\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        try:\n",
    "            #print(filename)\n",
    "            files.append(filename)\n",
    "            df = pd.read_csv(os.path.join(data_dir,filename))\n",
    "            \n",
    "            # Check the file has the columns that we need, and work out what the column names are for this file (annoyingly it changes)\n",
    "            date_col = \"Date\" # Doesn't change\n",
    "            count_col = \"Count\" if \"Count\" in df.columns else \"InCount\" # Two options\n",
    "            hour_col = \"Hour\" \n",
    "            loc_col = \"Location\" if \"Location\" in df.columns else \"LocationName\"\n",
    "            \n",
    "            if False in [date_col in df.columns, count_col in df.columns, hour_col in df.columns, loc_col in df.columns]:\n",
    "                raise Exception(\"File '{}' is missing a column. Date? {}, Count? {}, Hour? {}, Location? {}\".\n",
    "                      format(filename, date_col in df.columns, count_col in df.columns, hour_col in df.columns, loc_col in df.columns))\n",
    "                \n",
    "\n",
    "            # Check if any of the columns have nans\n",
    "            bad_cols = []\n",
    "            for x in [date_col, count_col, hour_col, loc_col]:\n",
    "                if True in df[x].isnull().values:\n",
    "                   bad_cols.append(x)\n",
    "            if len(bad_cols)>0:\n",
    "                failures.append(filename)\n",
    "                print(f\"File {filename} has nans in the following columns: '{str(bad_cols)}'. Ignoring it\")\n",
    "                continue\n",
    "\n",
    "            \n",
    "            # Create Series' that will represent each column\n",
    "            dates  = pd.to_datetime(df[date_col])\n",
    "            counts = pd.to_numeric(df[count_col])\n",
    "            hours  = convert_hour(df[hour_col]) # Hours can come in different forms \n",
    "            locs   = df[loc_col]\n",
    "            \n",
    "            # Derive a proper date from the date and hour\n",
    "            # (Almost certainly a more efficient way to do this using 'apply' or whatever)\n",
    "            dt     = pd.to_datetime(pd.Series( data = [date.replace(hour=hour) for date,hour in zip(dates,hours) ] ) )\n",
    "            \n",
    "            #df.apply(lambda x: x[date_col].replace(hour = x[hour_col]), axis=1)\n",
    "            \n",
    "            if False in [len(df) == len(x) for x in [dates, counts, hours, locs, dt]]:\n",
    "                raise Exception(\"One of the dataframe columns does not have enough values\")\n",
    "            total_rows += len(df)\n",
    "                \n",
    "            \n",
    "            # Create a temporary dataframe to represent the information in that file.\n",
    "            # Note that consistent column names (defined above) are used\n",
    "            frames.append(pd.DataFrame(data={\"Location\":locs, \"Date\":dates, \"Hour\":hours, \"Count\":counts, \"DateTime\":dt}))\n",
    "        except Exception as e:\n",
    "            print(\"Caught exception on file {}\".format(filename))\n",
    "            raise e\n",
    "            \n",
    "\n",
    "# Finally megre the frames into one big one\n",
    "merged_frames = pd.concat(frames)\n",
    "if total_rows != len(merged_frames):\n",
    "    raise Exception(f\"The number of rows in the individual files {total_rows} does \\\n",
    "not match those in the final dataframe {len(merged_frames)}.\")\n",
    "\n",
    "df = template.append(merged_frames)            \n",
    "print(f\"Finished. Made a dataframe with {len(df)} rows. {len(failures)}/{len(files)} files could not be read.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save as a csv file for reading elsewhere\n",
    "df.to_csv(\"data/lcc_footfall_combined.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Footfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekly fotfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newcastle Urban Observatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
